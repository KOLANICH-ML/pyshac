{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySHAC on tougher problems\n",
    "\n",
    "The earlier example was a basic example with a lot of easy possible answers, and although the search space was quite large, it did quite well in a short amount of time.\n",
    "\n",
    "However, a linear problem like that can be solved extremely easily using simple linear programming solvers, or even stochastic gradient descent techniques with a given initial value of `x` and `y`.\n",
    "\n",
    "Now, lets focus on a problem whose search space is limited, but it is not easy for optimization algorithms to get the correct answer !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pyshac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.sfu.ca/~ssurjano/branin.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://www.sfu.ca/~ssurjano/branin.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Branin function\n",
    "The branin search space is based on the equation below, where regular optimization algorithms might strugle.\n",
    "\n",
    "This function is usually evaluated on the square x1 ∈ [-5, 10], x2 ∈ [0, 15]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.sfu.ca/~ssurjano/branin2.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://www.sfu.ca/~ssurjano/branin2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The local minima of this function are the following two values : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.sfu.ca/~ssurjano/branin3.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://www.sfu.ca/~ssurjano/branin3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Branin evaluation function\n",
    "Below, lets define the `Branin` evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_branin(worker_id, params):\n",
    "    \"\"\" Code ported from https://www.sfu.ca/~ssurjano/Code/braninm.html\n",
    "    Global Minimum = -0.397887\n",
    "    \"\"\"\n",
    "\n",
    "    xx = list(params.values())\n",
    "    x1, x2 = xx[0], xx[1]\n",
    "\n",
    "    a = 1.0\n",
    "    b = 5.1 / (4 * (np.pi ** 2))\n",
    "    c = 5.0 / np.pi\n",
    "    r = 6.0\n",
    "    s = 10.0\n",
    "    t = 1.0 / (8.0 * np.pi)\n",
    "\n",
    "    term1 = a * ((x2 - b * (x1 ** 2) + c * x1 - r) ** 2)\n",
    "    term2 = s * (1.0 - t) * np.cos(x1)\n",
    "\n",
    "    out = term1 + term2 + s\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets test that the implementation is correct.\n",
    "# Optimal parameter 1\n",
    "x = [-np.pi, 12.275]\n",
    "\n",
    "params = OrderedDict()\n",
    "for i, xx in enumerate(x):\n",
    "    params['h%d' % i] = xx\n",
    "\n",
    "loss = evaluation_branin(0, params)\n",
    "assert np.allclose(loss, 0.397887)\n",
    "\n",
    "# Optimal parameter 2\n",
    "x = [np.pi, 2.275]\n",
    "\n",
    "params = OrderedDict()\n",
    "for i, xx in enumerate(x):\n",
    "    params['h%d' % i] = xx\n",
    "\n",
    "loss = evaluation_branin(0, params)\n",
    "assert np.allclose(loss, 0.397887)\n",
    "\n",
    "# Optimal parameter 3\n",
    "x = [9.42478, 2.475]\n",
    "\n",
    "params = OrderedDict()\n",
    "for i, xx in enumerate(x):\n",
    "    params['h%d' % i] = xx\n",
    "\n",
    "loss = evaluation_branin(0, params)\n",
    "assert np.allclose(loss, 0.397887)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_branin_hyperparameter_list():\n",
    "    h1 = pyshac.UniformContinuousHyperParameter('h1', -5.0, 10.0)\n",
    "    h2 = pyshac.UniformContinuousHyperParameter('h2', 0.0, 15.0)\n",
    "    return [h1, h2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the PySHAC Engine\n",
    "\n",
    "Branin is a harder problem than before, so lets allocate a larger budget and more larger number of samples in each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of workers possible : 10\n",
      "Using 10 parallel workers, it will require 20 epochs to fit 18 classifiers.\n",
      "Each classifier will be provided 10 samples to train per epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\yue\\pycharmprojects\\shac\\pyshac\\core\\engine.py:467: UserWarning: Number of workers exceeds 8 cores on device. Reducing parallel number of cores used to prevent resource starvation.\n",
      "  \"number of cores used to prevent resource starvation.\" % (cpu_count))\n"
     ]
    }
   ],
   "source": [
    "total_budget = 200\n",
    "num_batches = 20\n",
    "objective = 'min'\n",
    "\n",
    "params = get_branin_hyperparameter_list()\n",
    "shac = pyshac.SHAC(params, total_budget=total_budget,\n",
    "                   num_batches=num_batches, objective=objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 8 generator (loky backend) and 8 evaluator threads (loky backend) with a batch size of 10\n",
      "Beginning epoch 0001 out of 0020\n",
      "Number of classifiers availale = 0 (1 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:   10.2s remaining:   24.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:   10.3s remaining:   10.3s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:   10.4s remaining:    4.4s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:   10.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0070s.) Setting batch_size=56.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating 10 samples\n",
      "Finished evaluating 10 samples\n",
      "Finished training the 1-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    1 out of   20 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #1\n",
      "\n",
      "Beginning epoch 0002 out of 0020\n",
      "Number of classifiers availale = 1 (2 samples generated per accepted sample on average)\n",
      "Finished generating 10 samples\n",
      "Finished evaluating 10 samples\n",
      "Finished training the 2-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    2 out of   20 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0090s.) Setting batch_size=44.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0060s.) Setting batch_size=66.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0110s.) Setting batch_size=36.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0090s.) Setting batch_size=44.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialization of dataset done !\n",
      "Saved classifier #2\n",
      "\n",
      "Beginning epoch 0003 out of 0020\n",
      "Number of classifiers availale = 2 (4 samples generated per accepted sample on average)\n",
      "Finished generating 10 samples\n",
      "Finished evaluating 10 samples\n",
      "Finished training the 3-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    3 out of   20 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #3\n",
      "\n",
      "Beginning epoch 0004 out of 0020\n",
      "Number of classifiers availale = 3 (8 samples generated per accepted sample on average)\n",
      "Finished generating 10 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0140s.) Setting batch_size=28.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0120s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0170s.) Setting batch_size=22.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished evaluating 10 samples\n",
      "Finished training the 4-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    4 out of   20 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #4\n",
      "\n",
      "Beginning epoch 0005 out of 0020\n",
      "Number of classifiers availale = 4 (16 samples generated per accepted sample on average)\n",
      "Finished generating 10 samples\n",
      "Finished evaluating 10 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0080s.) Setting batch_size=50.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0250s.) Setting batch_size=14.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training the 5-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    5 out of   20 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #5\n",
      "\n",
      "Beginning epoch 0006 out of 0020\n",
      "Number of classifiers availale = 5 (32 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0080s.) Setting batch_size=50.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0350s.) Setting batch_size=10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating 10 samples\n",
      "Finished evaluating 10 samples\n",
      "Finished training the 6-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    6 out of   20 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #6\n",
      "\n",
      "Beginning epoch 0007 out of 0020\n",
      "Number of classifiers availale = 6 (64 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0020s.) Setting batch_size=1980.\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0100s.) Setting batch_size=40.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating 10 samples\n",
      "Finished evaluating 10 samples\n",
      "Finished training the 7-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    7 out of   20 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #7\n",
      "\n",
      "Beginning epoch 0008 out of 0020\n",
      "Number of classifiers availale = 7 (128 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    2.1s remaining:    5.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    2.4s remaining:    2.4s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    3.5s remaining:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0090s.) Setting batch_size=44.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating 10 samples\n",
      "Finished evaluating 10 samples\n",
      "Finished training the 8-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    8 out of   20 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #8\n",
      "\n",
      "Beginning epoch 0009 out of 0020\n",
      "Number of classifiers availale = 8 (256 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    1.4s remaining:    3.3s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    2.7s remaining:    2.7s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    5.2s remaining:    2.2s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    6.9s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0080s.) Setting batch_size=48.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating 10 samples\n",
      "Finished evaluating 10 samples\n",
      "Finished training the 9-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    9 out of   20 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #9\n",
      "\n",
      "Beginning epoch 0010 out of 0020\n",
      "Number of classifiers availale = 9 (512 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   3 out of  10 | elapsed:   12.4s remaining:   29.1s\n",
      "[Parallel(n_jobs=16)]: Done   5 out of  10 | elapsed:   16.4s remaining:   16.4s\n",
      "[Parallel(n_jobs=16)]: Done   7 out of  10 | elapsed:   22.7s remaining:    9.7s\n",
      "[Parallel(n_jobs=16)]: Done  10 out of  10 | elapsed:   27.3s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   5 out of  10 | elapsed:    3.3s remaining:    3.3s\n",
      "[Parallel(n_jobs=16)]: Done   7 out of  10 | elapsed:    3.3s remaining:    1.4s\n",
      "[Parallel(n_jobs=16)]: Done  10 out of  10 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating 10 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.2000s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished evaluating 10 samples\n",
      "Finished training the 10-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training   10 out of   20 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #10\n",
      "\n",
      "Beginning epoch 0011 out of 0020\n",
      "Number of classifiers availale = 10 (1024 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   3 out of  10 | elapsed:   23.8s remaining:   55.7s\n",
      "[Parallel(n_jobs=16)]: Done   5 out of  10 | elapsed:   27.6s remaining:   27.6s\n",
      "[Parallel(n_jobs=16)]: Done   7 out of  10 | elapsed:   30.8s remaining:   13.1s\n",
      "[Parallel(n_jobs=16)]: Done  10 out of  10 | elapsed:   42.3s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   5 out of  10 | elapsed:    3.2s remaining:    3.2s\n",
      "[Parallel(n_jobs=16)]: Done   7 out of  10 | elapsed:    3.3s remaining:    1.3s\n",
      "[Parallel(n_jobs=16)]: Done  10 out of  10 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating 10 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.1750s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished evaluating 10 samples\n",
      "Finished training the 11-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training   11 out of   20 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #11\n",
      "\n",
      "Beginning epoch 0012 out of 0020\n",
      "Number of classifiers availale = 11 (2048 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   3 out of  10 | elapsed:   34.6s remaining:  1.3min\n",
      "[Parallel(n_jobs=16)]: Done   5 out of  10 | elapsed:   48.3s remaining:   48.3s\n",
      "[Parallel(n_jobs=16)]: Done   7 out of  10 | elapsed:   50.6s remaining:   21.6s\n",
      "[Parallel(n_jobs=16)]: Done  10 out of  10 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   5 out of  10 | elapsed:    3.6s remaining:    3.6s\n",
      "[Parallel(n_jobs=16)]: Done   7 out of  10 | elapsed:    3.7s remaining:    1.5s\n",
      "[Parallel(n_jobs=16)]: Done  10 out of  10 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating 10 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.1900s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished evaluating 10 samples\n",
      "Finished training the 12-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training   12 out of   20 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #12\n",
      "\n",
      "Beginning epoch 0013 out of 0020\n",
      "Number of classifiers availale = 12 (4096 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   3 out of  10 | elapsed:   31.2s remaining:  1.2min\n",
      "[Parallel(n_jobs=16)]: Done   5 out of  10 | elapsed:  1.3min remaining:  1.3min\n",
      "[Parallel(n_jobs=16)]: Done   7 out of  10 | elapsed:  1.9min remaining:   48.1s\n",
      "[Parallel(n_jobs=16)]: Done  10 out of  10 | elapsed:  3.4min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   5 out of  10 | elapsed:    4.3s remaining:    4.3s\n",
      "[Parallel(n_jobs=16)]: Done   7 out of  10 | elapsed:    4.4s remaining:    1.8s\n",
      "[Parallel(n_jobs=16)]: Done  10 out of  10 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating 10 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.1680s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished evaluating 10 samples\n",
      "Finished training the 13-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training   13 out of   20 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #13\n",
      "\n",
      "Beginning epoch 0014 out of 0020\n",
      "Number of classifiers availale = 13 (8192 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   3 out of  10 | elapsed:  3.1min remaining:  7.3min\n",
      "[Parallel(n_jobs=16)]: Done   5 out of  10 | elapsed:  3.3min remaining:  3.3min\n",
      "[Parallel(n_jobs=16)]: Done   7 out of  10 | elapsed:  4.3min remaining:  1.9min\n",
      "[Parallel(n_jobs=16)]: Done  10 out of  10 | elapsed:  8.2min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating 10 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    5.2s remaining:   12.3s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    6.5s remaining:    6.5s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    6.6s remaining:    2.8s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    6.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished evaluating 10 samples\n",
      "Finished training the 14-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training   14 out of   20 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #14\n",
      "\n",
      "Beginning epoch 0015 out of 0020\n",
      "Number of classifiers availale = 14 (16384 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   3 out of  10 | elapsed:  5.0min remaining: 11.7min\n",
      "[Parallel(n_jobs=16)]: Done   5 out of  10 | elapsed: 10.0min remaining: 10.0min\n",
      "[Parallel(n_jobs=16)]: Done   7 out of  10 | elapsed: 13.4min remaining:  5.7min\n",
      "[Parallel(n_jobs=16)]: Done  10 out of  10 | elapsed: 18.7min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating 10 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    5.6s remaining:   13.2s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    6.2s remaining:    6.2s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    6.3s remaining:    2.6s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    6.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished evaluating 10 samples\n",
      "Finished training the 15-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training   15 out of   20 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #15\n",
      "\n",
      "Beginning epoch 0016 out of 0020\n",
      "Number of classifiers availale = 15 (32768 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   3 out of  10 | elapsed:  5.1min remaining: 11.9min\n",
      "[Parallel(n_jobs=16)]: Done   5 out of  10 | elapsed: 10.3min remaining: 10.3min\n",
      "[Parallel(n_jobs=16)]: Done   7 out of  10 | elapsed: 35.7min remaining: 15.3min\n"
     ]
    }
   ],
   "source": [
    "shac.fit(evaluation_branin, skip_cv_checks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets evaluate our engine\n",
    "As we saw before, there are two possible parameter settings that obtain the global parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.sfu.ca/~ssurjano/branin3.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://www.sfu.ca/~ssurjano/branin3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found and restored dataset containing 180 samples\n",
      "Found and restored 18 classifiers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shac.restore_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating after training\n",
      "Evaluating 1 batches (for a total of 5 samples) with 16 generator (loky backend)\n",
      "Number of classifiers availale = 16 (65536 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   2 out of   5 | elapsed:  3.5min remaining:  5.3min\n",
      "[Parallel(n_jobs=16)]: Done   3 out of   5 | elapsed:  5.1min remaining:  3.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted mean :  0.40167554090789004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   5 out of   5 | elapsed:  7.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   5 out of   5 | elapsed:  7.3min finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating after training\")\n",
    "predictions = shac.predict(5, max_classfiers=16)\n",
    "pred_evals = [evaluation_branin(0, pred) for pred in predictions]\n",
    "pred_mean = np.mean(pred_evals)\n",
    "\n",
    "print()\n",
    "print(\"Predicted mean : \", pred_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
