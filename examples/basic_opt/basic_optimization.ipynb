{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Basic Optimization of Search Space with PySHAC\n",
    "\n",
    "PySHAC is a lightweight library that can be used in any case where there exists a large search space, either discrete or continious, and we need to evaluate parameters of the search space to optimize some objective function.\n",
    "\n",
    "An easy use case is hyper parameter optimization, and a more advanced case is to perform Neural Architecture Search. In either case, we deal with large search spaces - in terms of hyper parameter combinations and in terms of the model architecture choices that we can construct.\n",
    "\n",
    "Let's first try pyshac out on a small search space - finding two parameters (which can take continious values) and try to find a linear combination to maximize some objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyshac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "Lets try to find two parameters - `x` and `y` such that the linear combination such that $$f(x, y) = 2 * x - y$$\n",
    "\n",
    "Lets consider that `f(x, y)` must be equal to some number (or at least close to it). This is an un-constrained problem, with a large number of possible answers. \n",
    "\n",
    "Let's assume that f(x, y) must be close to some number, say 4.0. This is arbitrary, and can be changed below. Now we need some notion of a loss metric, to detail how far `f` is from the value of 4.0. Let's use the most common metric of squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The value that `f` needs to get close to\n",
    "value = 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Hyper Parameters\n",
    "First, lets define the search space for the function. As per our function, we need two parameters `x` and `y` so that the function can compute its value.\n",
    "\n",
    "A Hyper Parameter is the basis of defining a search space in PySHAC. There are 3 specific parameters that we can declare :\n",
    "\n",
    "1) `DiscreteHyperParameter`: These are used to declare search spaces that take discrete values. These are most useful when defining hyper parameter optimization or architecture search spaces.\n",
    "\n",
    "2) `UniformContiniousHyperParameter` / `NormalContiniousHyperParameter`: These are continious hyper parameters that can sample from some distribution. Usually, we would use the Uniform version.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameters\n",
    "param_x = pyshac.UniformContinuousHyperParameter('x', -5.0, 5.0)\n",
    "param_y = pyshac.UniformContinuousHyperParameter('y', -2.0, 2.0)\n",
    "\n",
    "parameters = [param_x, param_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation functions\n",
    "PySHAC will require an objective function that it tries to optimize (can be either maximization or minimization).\n",
    "\n",
    "PySHAC's evaluation functions are quite simple to setup. An evaluation function has two inputs that it has to accept : \n",
    "\n",
    "1) id: An integer value representing the id of the thread or the executor. This is useful to decide which GPU to place operations on and compute values when using Tensorflow or Keras.\n",
    "\n",
    "2) parameters: An ordered dictionary of HyperParameters, in the order that they will be supplied to the engine. This is useful to get the values of the search space in a simple dictionary format, or as a list of values using `parameters.values()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the evaluation function\n",
    "def squared_error_loss(id, parameters):\n",
    "    x = parameters['x']\n",
    "    y = parameters['y']\n",
    "    y_sample = 2 * x - y\n",
    "\n",
    "    return np.square(y_sample - value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Budgeted computation\n",
    "\n",
    "PySHAC is built for limiting the amount of computation required to arrive at a useful result. We declare these budgets with two variables - \n",
    "\n",
    "1) `total budget`: Maximum number of evaluations that the pyshac engine will perform. This is the total number of evaluations, and is useful to set this budget when each evaluation is expensive. Consider having to train a new model for 20 epochs each time to obtain its accuracy as the evaluation metric.\n",
    "\n",
    "2) `num batches`: Declares how to divide the entire search space into batches. In doing so, you also define how many times the search space will be halved.\n",
    "\n",
    "3) Normally, the objective function passed is considered to be a loss function, which is minimized. We can also pass a directive to the engine, to maximize the objective function instead.\n",
    "\n",
    "4) Maximum number of classifiers that should be used. In certain cases, the search space is not large enough to warrant the upper limit of 18 classifiers (which divides the search space 2 ^ 18 times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the total budget as 100 evaluations\n",
    "total_budget = 100  # 100 evaluations at maximum\n",
    "\n",
    "# define the number of batches\n",
    "num_batches = 10  # 10 samples per batch\n",
    "\n",
    "# define the objective\n",
    "objective = 'min'  # minimize the squared loss\n",
    "\n",
    "max_classifiers = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySHAC Engine\n",
    "There are several engines available to PySHAC, which should be used in specific cases or task that is being performed. PySHAC has support for Tensorflow, Keras and Numpy / PyTorch libraries.\n",
    "\n",
    "An engines task is to sequentially halve the search space after each batch such that the objective function is optimized. For that it requires the above 4 parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of workers possible : 10\n",
      "Using 10 parallel workers, it will require 10 epochs to fit 9 classifiers.\n",
      "Each classifier will be provided 10 samples to train per epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\yue\\pycharmprojects\\shac\\pyshac\\core\\engine.py:467: UserWarning: Number of workers exceeds 8 cores on device. Reducing parallel number of cores used to prevent resource starvation.\n",
      "  \"number of cores used to prevent resource starvation.\" % (cpu_count))\n"
     ]
    }
   ],
   "source": [
    "shac = pyshac.SHAC(parameters, total_budget, num_batches, objective, max_classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the PySHAC Engine\n",
    "\n",
    "PySHAC is inspired by the Scikit-learn framework, and has simple functions to train and evaluate the engine.\n",
    "\n",
    "The `fit` method has 3 options which allow faster computation in exchange for some loss in the evaluation performance.\n",
    "\n",
    "1) `skip_cv_checks`: Usually, PySHAC will perform 5 fold cross validation on the results of each batch to get a more robust model. However, this may sometimes fail if the results of a batch are not discriminative enough to allow 5 fold training. In such a case, that entire batch will be not be used to train a classifier, and the engine moves onto the next batch. To prevent this wastage, this flag can be set to False. However, note that this will reduce the performance of the engine significantly in finding good hyper parameter combinations from the search space.\n",
    "\n",
    "2) `early_stop`: If at any point the engine fails to train a new classifier, there is a high chance that it may have reduced the search space as much as it could and may fail at the subsequent rounds as well. You can optionally stop training to prevent wasted computations.\n",
    "\n",
    "3) `relax_checks`: If the number of classifiers is large enough, the engine may fail to reduce the search space any longer, in which case it can either stop early or find more batch samples to try again. Another option is to simply relax the check that each subsequent classifier reduce the space further, and simply accept the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 8 generator (loky backend) and 8 evaluator threads (loky backend) with a batch size of 10\n",
      "Beginning epoch 0001 out of 0010\n",
      "Number of classifiers availale = 0 (1 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    9.8s remaining:   23.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    9.8s remaining:    9.8s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    9.8s remaining:    4.1s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    9.8s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0380s.) Setting batch_size=10.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating 10 samples\n",
      "Finished evaluating 10 samples\n",
      "Finished training the 1-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    1 out of   10 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #1\n",
      "\n",
      "Beginning epoch 0002 out of 0010\n",
      "Number of classifiers availale = 1 (2 samples generated per accepted sample on average)\n",
      "Finished generating 10 samples\n",
      "Finished evaluating 10 samples\n",
      "Finished training the 2-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    2 out of   10 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #2\n",
      "\n",
      "Beginning epoch 0003 out of 0010\n",
      "Number of classifiers availale = 2 (4 samples generated per accepted sample on average)\n",
      "Finished generating 10 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0080s.) Setting batch_size=48.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0050s.) Setting batch_size=78.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0060s.) Setting batch_size=66.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0260s.) Setting batch_size=14.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished evaluating 10 samples\n",
      "Finished training the 3-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    3 out of   10 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #3\n",
      "\n",
      "Beginning epoch 0004 out of 0010\n",
      "Number of classifiers availale = 3 (8 samples generated per accepted sample on average)\n",
      "Finished generating 10 samples\n",
      "Finished evaluating 10 samples\n",
      "Finished training the 4-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    4 out of   10 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #4\n",
      "\n",
      "Beginning epoch 0005 out of 0010\n",
      "Number of classifiers availale = 4 (16 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0090s.) Setting batch_size=44.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0080s.) Setting batch_size=50.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0110s.) Setting batch_size=36.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0090s.) Setting batch_size=44.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating 10 samples\n",
      "Finished evaluating 10 samples\n",
      "Finished training the 5-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    5 out of   10 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #5\n",
      "\n",
      "Beginning epoch 0006 out of 0010\n",
      "Number of classifiers availale = 5 (32 samples generated per accepted sample on average)\n",
      "Finished generating 10 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0110s.) Setting batch_size=36.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0070s.) Setting batch_size=56.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0210s.) Setting batch_size=18.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished evaluating 10 samples\n",
      "Finished training the 6-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    6 out of   10 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #6\n",
      "\n",
      "Beginning epoch 0007 out of 0010\n",
      "Number of classifiers availale = 6 (64 samples generated per accepted sample on average)\n",
      "Finished generating 10 samples\n",
      "Finished evaluating 10 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0080s.) Setting batch_size=48.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0450s.) Setting batch_size=8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training the 7-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    7 out of   10 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #7\n",
      "\n",
      "Beginning epoch 0008 out of 0010\n",
      "Number of classifiers availale = 7 (128 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0020s.) Setting batch_size=1594.\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0080s.) Setting batch_size=48.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating 10 samples\n",
      "Finished evaluating 10 samples\n",
      "Finished training the 8-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    8 out of   10 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #8\n",
      "\n",
      "Beginning epoch 0009 out of 0010\n",
      "Number of classifiers availale = 8 (256 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0250s.) Setting batch_size=14.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0070s.) Setting batch_size=56.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating 10 samples\n",
      "Finished evaluating 10 samples\n",
      "Finished training the 9-th classifier\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training    9 out of   10 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #9\n",
      "\n",
      "Beginning epoch 0010 out of 0010\n",
      "Number of classifiers availale = 9 (512 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0400s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=16)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done   5 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done   7 out of  10 | elapsed:    1.4s remaining:    0.5s\n",
      "[Parallel(n_jobs=16)]: Done  10 out of  10 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0030s.) Setting batch_size=1066.\n",
      "[Parallel(n_jobs=16)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating 10 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished evaluating 10 samples\n",
      "Finished training the 10-th classifier\n",
      "Cannot train any more models as maximum number of models has been reached.\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "\n",
      "\n",
      "Finished training   10 out of   10 epochs\n",
      "\n",
      "Serializing data and models\n",
      "Serializing dataset...\n",
      "Serialization of dataset done !\n",
      "Saved classifier #9\n",
      "\n",
      "Finished training all models !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    4.3s remaining:   10.2s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  10 | elapsed:    4.3s remaining:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    4.4s remaining:    1.8s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    4.4s finished\n"
     ]
    }
   ],
   "source": [
    "shac.fit(squared_error_loss, skip_cv_checks=True, early_stop=False, relax_checks=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restoring the engine\n",
    "\n",
    "Once PySHAC has trained an engine, it serializes the information and the classifiers to a directory called `shac` at the root of the directory where it was run.\n",
    "\n",
    "You could then construct an empty engine, and restore the values to that engine from that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found and restored dataset containing 100 samples\n",
      "Found and restored 9 classifiers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shac.restore_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting good hyper parameters\n",
    "\n",
    "After training, the engine can be used to sample good hyper parameters from the search space. However there is something to note: \n",
    "\n",
    "As the number of classifiers increases, the average number of samples from the search space that is required before the engine finds a good parameter is close to 2 ^ (number of classifiers). \n",
    "\n",
    "If you use all 18 classifiers, it can take a while even for a single sample to be obtained !\n",
    "\n",
    "Therefore, if you don't need all of the classifiers for the best predictions, you can use `max_classifiers` parameter in `predict` to obtain a good enough fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 batches (for a total of 20 samples) with 8 generator (loky backend)\n",
      "Number of classifiers availale = 9 (512 samples generated per accepted sample on average)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:   10.2s remaining:   30.7s\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:   10.2s remaining:   17.1s\n",
      "[Parallel(n_jobs=8)]: Done   4 out of   8 | elapsed:   10.3s remaining:   10.3s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:   10.3s remaining:    6.1s\n",
      "[Parallel(n_jobs=8)]: Done   6 out of   8 | elapsed:   10.3s remaining:    3.4s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:   10.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:   10.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   6 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   6 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   6 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Batch computation too fast (0.0858s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=8)]: Done   4 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done   4 out of   4 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# sample more than one batch of hyper parameters\n",
    "parameter_samples = shac.predict(20)  # samples 20 hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets evaluate the predicted samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1 : (1.7043, -0.2452). f(x, y) = 3.6538\n",
      "Sample 2 : (1.3181, -1.1737). f(x, y) = 3.8098\n",
      "Sample 3 : (1.4302, -0.9667). f(x, y) = 3.8270\n",
      "Sample 4 : (1.6817, -1.0739). f(x, y) = 4.4373\n",
      "Sample 5 : (1.4596, -0.6395). f(x, y) = 3.5586\n",
      "Sample 6 : (1.2671, -0.3822). f(x, y) = 2.9165\n",
      "Sample 7 : (1.6809, -1.0600). f(x, y) = 4.4218\n",
      "Sample 8 : (1.3511, -0.4537). f(x, y) = 3.1560\n",
      "Sample 9 : (1.3414, -0.8756). f(x, y) = 3.5583\n",
      "Sample 10 : (1.4383, -0.8550). f(x, y) = 3.7316\n",
      "Sample 11 : (1.3617, -0.5072). f(x, y) = 3.2306\n",
      "Sample 12 : (1.7481, -0.5372). f(x, y) = 4.0334\n",
      "Sample 13 : (1.7414, -0.7551). f(x, y) = 4.2379\n",
      "Sample 14 : (1.3671, -1.2492). f(x, y) = 3.9833\n",
      "Sample 15 : (1.6071, -0.7078). f(x, y) = 3.9220\n",
      "Sample 16 : (1.4999, -0.5197). f(x, y) = 3.5195\n",
      "Sample 17 : (1.4771, -0.4925). f(x, y) = 3.4467\n",
      "Sample 18 : (1.4425, -1.3390). f(x, y) = 4.2240\n",
      "Sample 19 : (1.6438, -1.3274). f(x, y) = 4.6150\n",
      "Sample 20 : (1.7102, -0.0834). f(x, y) = 3.5037\n",
      "\n",
      "Mean squared error of samples :  0.23855590148821998\n"
     ]
    }
   ],
   "source": [
    "losses = [squared_error_loss(0, params) for params in parameter_samples]\n",
    "x_list = [param['x'] for param in parameter_samples]\n",
    "y_list = [param['y'] for param in parameter_samples]\n",
    "\n",
    "for i, (x, y) in enumerate(zip(x_list, y_list)):\n",
    "    print(\"Sample %d : (%0.4f, %0.4f). f(x, y) = %0.4f\" % (i + 1, x, y, 2. * x - y))\n",
    "\n",
    "print()\n",
    "print(\"Mean squared error of samples : \", np.mean(losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
